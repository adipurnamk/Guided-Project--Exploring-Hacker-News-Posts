{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "### Python for Data Science: Intermediate, Dataquest\n",
    "---\n",
    "\n",
    "![HN Logo](https://s3.amazonaws.com/dq-content/354/hacker_news.jpg)\n",
    "\n",
    "In this project, we'll work with a data set of submissions to popular technology site Hacker News.\n",
    "\n",
    "Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "You can find the data set here, but note that it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions. Below are descriptions of the columns:\n",
    "\n",
    ">**id**: The unique identifier from Hacker News for the post  \n",
    "**title**: The title of the post  \n",
    "**url**: The URL that the posts links to, if it the post has a URL  \n",
    "**num_points**: The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes  \n",
    "**num_comments**: The number of comments that were made on the post  \n",
    "**author**: The username of the person who submitted the post  \n",
    "**created_at**: The date and time at which the post was submitted\n",
    "\n",
    "We're specifically interested in posts whose titles begin with either **Ask HN** or **Show HN**.  \n",
    "We'll compare these two types of posts to determine the following:\n",
    "\n",
    "* Do Ask HN or Show HN receive more comments on average?\n",
    "* Do posts created at a certain time receive more comments on average?  \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by importing the libraries we need and reading the data set into a list of lists.\n",
    "from csv import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'],\n",
       " ['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the hacker_news.csv file in as a list of lists.\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "\n",
    "# Display the first five rows of hn.\n",
    "hn[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the first list in the inner lists contains the column headers, and the lists after contain the data for one row. In order to analyze our data, we need to first remove the row containing the column headers. Let's remove that first row next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the first row of data, and assign it to the variable headers.\n",
    "header = hn[0]\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01'],\n",
       " ['10301696',\n",
       "  'Note by Note: The Making of Steinway L1037 (2007)',\n",
       "  'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0',\n",
       "  '8',\n",
       "  '2',\n",
       "  'walterbell',\n",
       "  '9/30/2015 4:12']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the first row from hn.\n",
    "hn = hn[1:]\n",
    "\n",
    "# Display the first five rows of hn to verify that you removed the header row properly.\n",
    "hn[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've removed the headers from hn, we're ready to filter our data. Since we're only concerned with post titles beginning with **Ask HN** or **Show HN**, we'll create new lists of lists containing just the data for those titles.  \n",
    "\n",
    "To find the posts that begin with either **Ask HN** or **Show HN**, we'll use the string method startswith. Given a string object, say, string1, we can check if starts with, say, dq by inspecting the output of the object string1.startswith('dq'). If string1 starts with dq, it will return True, otherwise it will return False.  \n",
    "\n",
    "Let's use these methods to separate posts beginning with **Ask HN** and **Show HN** (and case variations) into two different lists next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "18938\n"
     ]
    }
   ],
   "source": [
    "# Create three empty lists called ask_posts, show_posts, and other_posts.\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    if title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "# Check the number of posts in ask_posts, show_posts, and other_posts.\n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last screen, we separated the \"ask posts\" and the \"show posts\" into two list of lists named ask_posts and show_posts.  \n",
    "Next, let's determine if ask posts or show posts receive more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12296411',\n",
       "  'Ask HN: How to improve my personal website?',\n",
       "  '',\n",
       "  '2',\n",
       "  '6',\n",
       "  'ahmedbaracat',\n",
       "  '8/16/2016 9:55'],\n",
       " ['10610020',\n",
       "  'Ask HN: Am I the only one outraged by Twitter shutting down share counts?',\n",
       "  '',\n",
       "  '28',\n",
       "  '29',\n",
       "  'tkfx',\n",
       "  '11/22/2015 13:43'],\n",
       " ['11610310',\n",
       "  'Ask HN: Aby recent changes to CSS that broke mobile?',\n",
       "  '',\n",
       "  '1',\n",
       "  '1',\n",
       "  'polskibus',\n",
       "  '5/2/2016 10:14'],\n",
       " ['12210105',\n",
       "  'Ask HN: Looking for Employee #3 How do I do it?',\n",
       "  '',\n",
       "  '1',\n",
       "  '3',\n",
       "  'sph130',\n",
       "  '8/2/2016 14:20'],\n",
       " ['10394168',\n",
       "  'Ask HN: Someone offered to buy my browser extension from me. What now?',\n",
       "  '',\n",
       "  '28',\n",
       "  '17',\n",
       "  'roykolak',\n",
       "  '10/15/2015 16:38']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_posts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total comments on ask posts:  24483\n"
     ]
    }
   ],
   "source": [
    "# Find the total number of comments in ask posts and assign it to total_ask_comments.\n",
    "total_ask_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    n_comments = int(row[4])\n",
    "    total_ask_comments += n_comments\n",
    "\n",
    "print(\"Total comments on ask posts: \",total_ask_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average comments on ask posts:  14.038417431192661\n"
     ]
    }
   ],
   "source": [
    "# Compute the average number of comments on ask posts and assign it to avg_ask_comments.\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "\n",
    "print(\"Average comments on ask posts: \", avg_ask_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we do the same step to show posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['10627194',\n",
       "  'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform',\n",
       "  'https://iot.seeed.cc',\n",
       "  '26',\n",
       "  '22',\n",
       "  'kfihihc',\n",
       "  '11/25/2015 14:03'],\n",
       " ['10646440',\n",
       "  'Show HN: Something pointless I made',\n",
       "  'http://dn.ht/picklecat/',\n",
       "  '747',\n",
       "  '102',\n",
       "  'dhotson',\n",
       "  '11/29/2015 22:46'],\n",
       " ['11590768',\n",
       "  'Show HN: Shanhu.io, a programming playground powered by e8vm',\n",
       "  'https://shanhu.io',\n",
       "  '1',\n",
       "  '1',\n",
       "  'h8liu',\n",
       "  '4/28/2016 18:05'],\n",
       " ['12178806',\n",
       "  'Show HN: Webscope  Easy way for web developers to communicate with Clients',\n",
       "  'http://webscopeapp.com',\n",
       "  '3',\n",
       "  '3',\n",
       "  'fastbrick',\n",
       "  '7/28/2016 7:11'],\n",
       " ['10872799',\n",
       "  'Show HN: GeoScreenshot  Easily test Geo-IP based web pages',\n",
       "  'https://www.geoscreenshot.com/',\n",
       "  '1',\n",
       "  '9',\n",
       "  'kpsychwave',\n",
       "  '1/9/2016 20:45']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_posts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total comments on show posts:  11988\n"
     ]
    }
   ],
   "source": [
    "# Find the total number of comments in show posts and assign it to total_show_comments.\n",
    "total_show_comments = 0\n",
    "\n",
    "for row in show_posts:\n",
    "    n_comments = int(row[4])\n",
    "    total_show_comments += n_comments\n",
    "\n",
    "print(\"Total comments on show posts: \",total_show_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average comments on show posts:  10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "# Compute the average number of comments on show posts and assign it to avg_show_comments.\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "\n",
    "print(\"Average comments on show posts: \", avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Average comments on ask posts:  14.038417431192661  \n",
    "> Average comments on show posts:  10.31669535283993\n",
    "\n",
    "> Average coment on ask post is more than on show posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last step, you should've determined that, on average, ask posts receive more comments than show posts. Since ask posts are more likely to receive comments, we'll focus our remaining analysis just on these posts.\n",
    "\n",
    "Next, we'll determine if ask posts created at a certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "\n",
    "1. Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "2. Calculate the average number of comments ask posts receive by hour created.\n",
    "\n",
    "In this step, we'll tackle the first step — calculating the amount of ask posts and comments by hour created. We'll use the datetime module to work with the data in the created_at column.  \n",
    "Let's use this technique to calculate the amount of ask posts created per hour, along with the total amount of comments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['8/16/2016 9:55', 6],\n",
       " ['11/22/2015 13:43', 29],\n",
       " ['5/2/2016 10:14', 1],\n",
       " ['8/2/2016 14:20', 3],\n",
       " ['10/15/2015 16:38', 17]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_list = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    created_at = row[6]\n",
    "    n_comments = int(row[4])\n",
    "    result_list.append([created_at, n_comments])\n",
    "\n",
    "result_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts by hour:  {9: 45, 13: 85, 10: 59, 14: 107, 16: 108, 23: 68, 12: 73, 17: 100, 15: 116, 21: 109, 20: 80, 2: 58, 18: 109, 3: 54, 5: 46, 19: 110, 1: 60, 22: 71, 8: 48, 4: 47, 0: 55, 6: 44, 7: 34, 11: 58}\n",
      "\n",
      "\n",
      "Comments by hour:  {9: 251, 13: 1253, 10: 793, 14: 1416, 16: 1814, 23: 543, 12: 687, 17: 1146, 15: 4477, 21: 1745, 20: 1722, 2: 1381, 18: 1439, 3: 421, 5: 464, 19: 1188, 1: 683, 22: 479, 8: 492, 4: 337, 0: 447, 6: 397, 7: 267, 11: 641}\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "dt_format = \"%m/%d/%Y %H:%M\"\n",
    "\n",
    "for row in result_list:\n",
    "    time = dt.datetime.strptime(row[0], dt_format)\n",
    "    hour = time.hour\n",
    "    \n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = row[1]\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += row[1]\n",
    "        \n",
    "print(\"Counts by hour: \", counts_by_hour)\n",
    "print(\"\\n\")\n",
    "print(\"Comments by hour: \", comments_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last step, we created two dictionaries:\n",
    "\n",
    "* counts_by_hour: contains the number of ask posts created during each hour of the day.\n",
    "* comments_by_hour: contains the corresponding number of comments ask posts created at each hour received.\n",
    "\n",
    "Next, we'll use these two dictionaries to calculate the average number of comments for posts created during each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 5.5777777777777775],\n",
       " [13, 14.741176470588234],\n",
       " [10, 13.440677966101696],\n",
       " [14, 13.233644859813085],\n",
       " [16, 16.796296296296298],\n",
       " [23, 7.985294117647059],\n",
       " [12, 9.41095890410959],\n",
       " [17, 11.46],\n",
       " [15, 38.5948275862069],\n",
       " [21, 16.009174311926607],\n",
       " [20, 21.525],\n",
       " [2, 23.810344827586206],\n",
       " [18, 13.20183486238532],\n",
       " [3, 7.796296296296297],\n",
       " [5, 10.08695652173913],\n",
       " [19, 10.8],\n",
       " [1, 11.383333333333333],\n",
       " [22, 6.746478873239437],\n",
       " [8, 10.25],\n",
       " [4, 7.170212765957447],\n",
       " [0, 8.127272727272727],\n",
       " [6, 9.022727272727273],\n",
       " [7, 7.852941176470588],\n",
       " [11, 11.051724137931034]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hour in comments_by_hour:\n",
    "    average = comments_by_hour[hour] / counts_by_hour[hour]\n",
    "    avg_by_hour.append([hour, average])\n",
    "    \n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last step, we calculated the average number of comments for posts created during each hour of the day, and stored the results in a list of lists named avg_by_hour.\n",
    "\n",
    "Although we now have the results we need, this format makes it hard to identify the hours with the highest values. Let's finish by sorting the list of lists and printing the five highest values in a format that's easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.5777777777777775, 9],\n",
       " [14.741176470588234, 13],\n",
       " [13.440677966101696, 10],\n",
       " [13.233644859813085, 14],\n",
       " [16.796296296296298, 16],\n",
       " [7.985294117647059, 23],\n",
       " [9.41095890410959, 12],\n",
       " [11.46, 17],\n",
       " [38.5948275862069, 15],\n",
       " [16.009174311926607, 21],\n",
       " [21.525, 20],\n",
       " [23.810344827586206, 2],\n",
       " [13.20183486238532, 18],\n",
       " [7.796296296296297, 3],\n",
       " [10.08695652173913, 5],\n",
       " [10.8, 19],\n",
       " [11.383333333333333, 1],\n",
       " [6.746478873239437, 22],\n",
       " [10.25, 8],\n",
       " [7.170212765957447, 4],\n",
       " [8.127272727272727, 0],\n",
       " [9.022727272727273, 6],\n",
       " [7.852941176470588, 7],\n",
       " [11.051724137931034, 11]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "\n",
    "swap_avg_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "\n",
      "15:00: 38.59 average comments per post\n",
      "2:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "print(\"Top 5 Hours for Ask Posts Comments\\n\")\n",
    "for row in sorted_swap[:5]:\n",
    "   print(\"{}:00: {:.2f} average comments per post\".format(row[1], row[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "If we refer back to the original dataset in [Kaggle](https://www.kaggle.com/hacker-news/hacker-news-posts), this dataset is based on Eastern Time in the US. If we live there, we should consider asking a question in Hacker News at 15:00. At that time is more possibility of the answer to be answered than the other time.  \n",
    "Another time we should consider to post question is at 2:00, 20:00, 16:00, or 21:00\n",
    "\n",
    "Since I lived in Western Indonesia (GMT+7), Eastern Daylight Time is 11 hours behind Western Indonesian Time. So, we add 11 hours to the recommended time.  \n",
    "For Western Indonesian should consider posting a question at 2:00. Then 13:00, 19:00, 3:00, or 8:00.  \n",
    "Maybe it's difficult for us to post at 2:00, it sleeping time actually, except for some of us who are nocturnal. The ideal time for usual people maybe after lunchtime at 13:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
